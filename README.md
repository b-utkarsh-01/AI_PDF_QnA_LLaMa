# ğŸ¤– AI PDF Q&A Web App

AI-powered web app to upload PDFs and ask questions based on their content using a locally hosted LLaMA (Mistral 7B) model.

---



## ğŸ¬ Demo

ğŸ“½ï¸ [Watch the demo video](https://www.youtube.com/watch?v=YOUR_VIDEO_ID)

Below is a quick preview:

![Demo Preview](assets/demo-screenshot.gif)

---

## ğŸ§  Model Download

This app requires a local copy of the Mistral model in `.gguf` format.

ğŸ“¥ [Download `mistral-7b-instruct-v0.1.Q3_K_M.gguf`]([https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF](https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/blob/main/mistral-7b-instruct-v0.1.Q3_K_M.gguf))

ğŸ—‚ï¸ After downloading, place the model file here:

ğŸ§  Make sure `main.py` has the correct path:

```python
model = Llama(
    model_path="backend/models/mistral-7b-instruct-v0.1.Q3_K_M.gguf",
    ...
)

---

## ğŸ“¦ Project Structure
ğŸ“ AI_pdf_QnA_WebApp/ <br>
â”œâ”€â”€ main.py # FastAPI backend logic<br>
â”œâ”€â”€ models.py # SQLAlchemy document model<br>
â”œâ”€â”€ database.py # DB setup and session<br>
â”œâ”€â”€ index.html # TailwindCSS-based UI<br>
â”œâ”€â”€ script.js # Handles PDF upload + Q&A<br>
â”œâ”€â”€ uploads/ # Stores uploaded PDFs<br>
â”œâ”€â”€ models/ # Store your .gguf LLaMA model<br>
â””â”€â”€ README.md # Project documentation

---

## âœ¨ Features

- ğŸ“„ Upload PDF documents
- ğŸ” Ask questions based on document content
- ğŸ§  Local inference using Mistral 7B model
- ğŸ’¬ Chat-style Q&A interface
- ğŸ›¢ï¸ SQLite for document storage
- ğŸ¨ Responsive UI with TailwindCSS

---

## âš™ï¸ Setup Instructions

### 1. Clone this repository

```bash
git clone https://github.com/your-username/your-repo.git
cd your-repo

---

## âœ… Assignment Criteria Checklist

- âœ… **Functionality**  
  Upload PDF documents, extract content, and ask questions using an AI model â€” fully working end-to-end.

- âœ… **Code Quality**  
  Clean, well-organized codebase with modular structure and clear comments in both frontend and backend.

- âœ… **Design & UX**  
  Simple, intuitive user interface built with TailwindCSS â€” responsive layout and smooth interaction.

- âœ… **Innovation**  
  Uses a locally hosted LLaMA (Mistral 7B) model â€” no external API calls, ensuring privacy and performance.

---

## ğŸš€ Future Improvements

- ğŸ” **Vector-based document search (FAISS)**  
  Implement semantic search using document embeddings for faster and more accurate answers, especially for large PDFs.

- â±ï¸ **Stream answers instead of waiting for full response**  
  Improve user experience by streaming the AI's answer in real time instead of waiting for the complete response.

- ğŸ“Œ **Highlight relevant parts of the PDF**  
  Visually mark or reference the portion of the PDF text that the AI answer is based on, for better transparency and context.
